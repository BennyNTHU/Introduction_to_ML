{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這一部分我們要討論$\\textbf{主題建模}$。其意思是將為標記標籤的文本賦予主題。比方說我們想從電影文本資料集中反推評論來自哪幾類的電影(或著說，可以分為哪幾類電影的評論)。一個常用的技術較做$\\textbf{潛在狄利克雷分配}$，又稱為Latent Dirichlet Allocation (LDA)。\n",
    "LDA會找出最頻繁出現的單詞組合，並輸入前面討論的詞袋模型，分解成兩個新的矩陣輸出:\n",
    "\n",
    "1. 文件到主題矩陣\n",
    "2. 單字到主題矩陣\n",
    "\n",
    "其分解之依據為，兩個矩陣相乘後必須盡可能恢復輸入(詞袋矩陣)。因此我們要是先定義主題的數量(一個超參數)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
       "1  OK... so... I really like Kris Kristofferson a...          0\n",
       "2  ***SPOILER*** Do not read this, if you think a...          0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('movie_data.csv', encoding='utf-8')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer(stop_words='english',\n",
    "                        max_df=.1, # 頻率超過10%就視為沒有幫助。這是一個超參數\n",
    "                        max_features=5000) #待會一類別取5000個字作為特徵\n",
    "X = count.fit_transform(df['review'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們就假定能分成十個主題。'batch'是讓LDA估計器在一次的迭代中，基於所有可用的訓練數據(詞袋矩陣)來進行估計。雖然會比較慢，但會比線上學習快一點。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=10, # 10個主題\n",
    "                                random_state=123,\n",
    "                                learning_method='batch')\n",
    "X_topics = lda.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lda物件的屬性是一個10x5000的矩陣。5000個字詞依照重要性遞增排列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 5000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.components_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "來看看各類別前10重要的字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "worst minutes awful script stupid terrible money waste budget ll\n",
      "Topic 2:\n",
      "family mother father children girl loved kids watched friends feel\n",
      "Topic 3:\n",
      "american war dvd music tv history german black early america\n",
      "Topic 4:\n",
      "human audience cinema art sense feel viewer game different camera\n",
      "Topic 5:\n",
      "police guy car dead murder wife goes town killed crime\n",
      "Topic 6:\n",
      "horror house sex girl woman blood gore creepy scary night\n",
      "Topic 7:\n",
      "role performance comedy actor performances plays played play john excellent\n",
      "Topic 8:\n",
      "series episode war episodes tv season action star king western\n",
      "Topic 9:\n",
      "book version original read novel disney effects fi sci animation\n",
      "Topic 10:\n",
      "action fight guy guys cool fun minutes music nice fighting\n"
     ]
    }
   ],
   "source": [
    "n_top_words = 10\n",
    "feature_names = count.get_feature_names()\n",
    "\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    print(\"Topic %d:\" % (topic_idx + 1))\n",
    "    print(\" \".join([feature_names[i]\n",
    "                    for i in topic.argsort()\\\n",
    "                        [:-n_top_words - 1:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on reading the 10 most important words for each topic, we may guess that the LDA identified the following topics:\n",
    "    \n",
    "1. Generally bad movies (not really a topic category)\n",
    "2. Movies about families\n",
    "3. War movies\n",
    "4. Art movies\n",
    "5. Crime movies\n",
    "6. Horror movies\n",
    "7. Comedies\n",
    "8. Movies somehow related to TV shows\n",
    "9. Movies based on books\n",
    "10. Action movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To confirm that the categories make sense based on the reviews, let's plot 5 movies from the war movie category (category 3 at index position 2):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "War movie #1:\n",
      "In the 1980s in wrestling the world was simple. Hulk Hogan would take on Roddy Piper, or Bobby Heenan's cronies or Ted DiBiase and come out victorious more often than not. Occasionally he would get an ally like Randy Savage in 1988, but mostly it was all about Hulk Hogan vs Bobby Heenan, and that's  ...\n",
      "\n",
      "War movie #2:\n",
      "Hollywood Hotel was the last movie musical that Busby Berkeley directed for Warner Bros. His directing style had changed or evolved to the point that this film does not contain his signature overhead shots or huge production numbers with thousands of extras. By the last few years of the Thirties, sw ...\n",
      "\n",
      "War movie #3:\n",
      "This is a movie about the music that is currently being played in Istanbul. Istanbul was the center of the two Old World superpowers, the Byzantine Empire and the Ottoman Empire. Today, it is a megalopolis of almost 10 million. So it is to no ones surprise that a lot of music is being played in Ista ...\n"
     ]
    }
   ],
   "source": [
    "horror = X_topics[:, 2].argsort()[::-1]\n",
    "\n",
    "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
    "    print('\\nWar movie #%d:' % (iter_idx + 1))\n",
    "    print(df['review'][movie_idx][:300], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ㄜ...換1看看好了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generally bad movies movie #1:\n",
      "I went into this with my hopes up, by twenty minutes into the movie I couldn't have been more let down. Despite thinking that this would be another horribly bad remake, I kept my hopes high that maybe...just maybe someone would get it right this time around. Sadly, Prom Night is about on the same qu ...\n",
      "\n",
      "Generally bad movies movie #2:\n",
      "It used to be that video distributors like Sub Rosa and Brain Damage Films would release low-budget, shot-on-video horror films to a select market of gorehounds that ate them up with glee. That's acceptable to me, because you could see these movies from a mile away with their shoddy box art and chee ...\n",
      "\n",
      "Generally bad movies movie #3:\n",
      "It seems like anybody can make a movie nowadays. It's like all you need is a camera, a group of people to be your cast and crew, a script, and a little money and walla you have a movie. Problem is that talent isn't always part of this equation and often times these kind of low budget films turn out  ...\n"
     ]
    }
   ],
   "source": [
    "horror = X_topics[:, 0].argsort()[::-1]\n",
    "\n",
    "for iter_idx, movie_idx in enumerate(horror[:3]):\n",
    "    print('\\nGenerally bad movies movie #%d:' % (iter_idx + 1))\n",
    "    print(df['review'][movie_idx][:300], '...')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
